{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='top'></a>\n",
    "\n",
    "# CSCI 3202, Spring 2020\n",
    "# Assignment 3\n",
    "# Due:  Wednesday 4 March 2020 by 11:59 PM\n",
    "\n",
    "<br>\n",
    "\n",
    "### Your name: Muntaha Pasha\n",
    "\n",
    "<br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some things that might be useful**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy as cp\n",
    "from scipy import stats\n",
    "from math import floor\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from time import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "## Problem 1 (35 points):  Playing \"intelligent\" Tic-Tac-Toe\n",
    "\n",
    "<img src=\"https://www.cookieshq.co.uk/images/2016/06/01/tic-tac-toe.png\" width=\"150\"/>\n",
    "\n",
    "<a id='p2a'></a>\n",
    "\n",
    "### (1a)   Defining the Tic-Tac-Toe class structure\n",
    "\n",
    "Fill in this class structure for Tic-Tac-Toe using what we did during class as a guide.\n",
    "* `moves` is a list of tuples to represent which moves are available. Recall that we are using matrix notation for this, where the upper-left corner of the board, for example, is represented at (1,1).\n",
    "* `result(self, move, state)` returns a ***hypothetical*** resulting `State` object if `move` is made when the game is in the current `state`\n",
    "* `compute_utility(self, move, state)` calculates the utility of `state` that would result if `move` is made when the game is in the current `state`. This is where you want to check to see if anyone has gotten `nwin` in a row\n",
    "* `game_over(self, state)` - this wasn't a method, but it should be - it's a piece of code we need to execute repeatedly and giving it a name makes clear what task the piece of code performs. Returns `True` if the game in the given `state` has reached a terminal state, and `False` otherwise.\n",
    "* `utility(self, state, player)` also wasn't a method earlier, but also should be.  Returns the utility of the current state if the player is X and $-1 \\cdot$ utility if the player is O.\n",
    "* `display(self)` is a method to display the current game `state`, You get it for free! because this would be super frustrating without it.\n",
    "* `play_game(self, player1, player2)` returns an integer that is the utility of the outcome of the game (+1 if X wins, 0 if draw, -1 if O wins). `player1` and `player2` are functional arguments that we will deal with in parts **2b** and **2d**.\n",
    "\n",
    "Some notes:\n",
    "* Assume X always goes first.\n",
    "* Do **not** hard-code for 3x3 boards.\n",
    "* You may add attributes and methods to these classes as needed for this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SOURCES USED:**\n",
    "\n",
    "1 - (Get in Python) https://stackoverflow.com/questions/2068349/understanding-get-method-in-python\n",
    "\n",
    "2 - (Class Definitions came from In-Class Notebook for Tic-Tac-Toe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State:\n",
    "    def __init__(self, moves):\n",
    "        self.to_move = 'X'\n",
    "        self.utility = 0\n",
    "        self.board = {}\n",
    "        self.moves = moves\n",
    "\n",
    "class TicTacToe:\n",
    "    def __init__(self, nrow=3, ncol=3, nwin=3, nexp=0):\n",
    "        self.nrow = nrow\n",
    "        self.ncol = ncol\n",
    "        self.nwin = nwin\n",
    "        self.nexp = nexp\n",
    "        #Adding a value to keep track of expanded states.\n",
    "        self.expandedStateVar = 0\n",
    "        moves = [(row, col) for row in range(1, nrow + 1) for col in range(1, ncol + 1)]\n",
    "        self.state = State(moves)\n",
    "\n",
    "    def result(self, move, state):\n",
    "        '''\n",
    "        What is the hypothetical result of move `move` in state `state` ?\n",
    "        move  = (row, col) tuple where player will put their mark (X or O)\n",
    "        state = a `State` object, to represent whose turn it is and form\n",
    "                the basis for generating a **hypothetical** updated state\n",
    "                that will result from making the given `move`\n",
    "        '''\n",
    "        # Don't do anything if the move isn't a legal one\n",
    "        if move not in state.moves:\n",
    "            return state\n",
    "        # Return a copy of the updated state:\n",
    "        #   compute utility, update the board, remove the move, update whose turn\n",
    "        new_state = cp.deepcopy(state)\n",
    "        new_state.utility = self.compute_utility(move, state)\n",
    "        new_state.board[move] = state.to_move\n",
    "        new_state.moves.remove(move)\n",
    "        new_state.to_move = ('O' if state.to_move == 'X' else 'X')\n",
    "        return new_state\n",
    "\n",
    "    def compute_utility(self, move, state):\n",
    "        '''\n",
    "        What is the utility of making move `move` in state `state`?\n",
    "        If 'X' wins with this move, return 1;\n",
    "        if 'O' wins return -1;\n",
    "        else return 0.\n",
    "        '''        \n",
    "        row, col = move\n",
    "        player = state.to_move\n",
    "        \n",
    "        # create a hypothetical copy of the board, with 'move' executed\n",
    "        board = cp.deepcopy(state.board)\n",
    "        board[move] = player\n",
    "\n",
    "        # what are all the ways 'player' could with with 'move'?\n",
    "        \n",
    "        # check for row-wise win\n",
    "        in_a_row = 0\n",
    "        for c in range(1,self.ncol+1):\n",
    "            in_a_row += board.get((row,c))==player\n",
    "\n",
    "        # check for column-wise win\n",
    "        in_a_col = 0\n",
    "        for r in range(1,self.nrow+1):\n",
    "            in_a_col += board.get((r,col))==player\n",
    "\n",
    "        # check for NW->SE diagonal win\n",
    "        in_a_diag1 = 0\n",
    "        for r in range(row,0,-1):\n",
    "            in_a_diag1 += board.get((r,col-(row-r)))==player\n",
    "        for r in range(row+1,self.nrow+1):\n",
    "            in_a_diag1 += board.get((r,col-(row-r)))==player\n",
    "\n",
    "        # check for SW->NE diagonal win\n",
    "        in_a_diag2 = 0\n",
    "        for r in range(row,0,-1):\n",
    "            in_a_diag2 += board.get((r,col+(row-r)))==player\n",
    "        for r in range(row+1,self.nrow+1):\n",
    "            in_a_diag2 += board.get((r,col+(row-r)))==player\n",
    "        \n",
    "        if self.nwin in [in_a_row, in_a_col, in_a_diag1, in_a_diag2]:\n",
    "            return 1 if player=='X' else -1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def game_over(self, state):\n",
    "        '''game is over if someone has won (utility!=0) or there\n",
    "        are no more moves left'''\n",
    "        return state.utility!=0 or len(state.moves)==0    \n",
    "\n",
    "    def utility(self, state, player):\n",
    "        '''Return the value to player; 1 for win, -1 for loss, 0 otherwise.'''\n",
    "        return state.utility if player=='X' else -state.utility\n",
    "\n",
    "    def display(self):\n",
    "        board = self.state.board\n",
    "        for row in range(1, self.nrow + 1):\n",
    "            for col in range(1, self.ncol + 1):\n",
    "                print(board.get((row, col), '.'), end=' ')\n",
    "            print()\n",
    "\n",
    "    def play_game(self, player1, player2):\n",
    "        '''Play a game of tic-tac-toe!'''\n",
    "        turn_limit = self.nrow*self.ncol  # limit in case of buggy code\n",
    "        turn = 0\n",
    "        while turn<=turn_limit:\n",
    "            for player in [player1, player2]:\n",
    "                turn += 1\n",
    "                move = player(self)\n",
    "                self.state = self.result(move, self.state)\n",
    "                if self.game_over(self.state):\n",
    "                    #self.display()\n",
    "                    return self.state.utility                \n",
    "def random_player(game):\n",
    "    '''A player that chooses a legal move at random.'''\n",
    "    possible_actions = game.state.moves\n",
    "    return possible_actions[np.random.randint(low=0, high=len(possible_actions))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "\n",
    "### (1b) Define a random player\n",
    "\n",
    "Define a function `random_player` that takes a single argument of the `TicTacToe` class and returns a random move out of the available legal moves in the `state` of the `TicTacToe` game.\n",
    "\n",
    "In your code for the `play_game` method above, make sure that `random_player` could be a viable input for the `player1` and/or `player2` arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the Scores for Player 1\n",
      "------------------------------\n",
      "Wins: 59.375%\n",
      "Losses: 29.125%\n",
      "Ties: 11.5%\n"
     ]
    }
   ],
   "source": [
    "def random_player(arg1):\n",
    "    actionsAvailable = arg1.state.moves\n",
    "    moves = np.random.choice(len(actionsAvailable), 1)[0]\n",
    "    randomMove = actionsAvailable[moves]\n",
    "    return randomMove\n",
    "\n",
    "#Winings\n",
    "WinningGames = 0\n",
    "#Losses\n",
    "LosingGames = 0\n",
    "#Ties\n",
    "TiedGames = 0\n",
    "#For 800 games...\n",
    "for i in range(800):\n",
    "    #Play Tic-Tac-Toe on a 3x3 board\n",
    "    GamePlayed = TicTacToe(3,3,3)\n",
    "    #Calculate the Score\n",
    "    Score = GamePlayed.play_game(random_player, random_player)\n",
    "    if Score == 1:\n",
    "        WinningGames = WinningGames + 1\n",
    "    elif Score == -1:\n",
    "        LosingGames = LosingGames + 1\n",
    "    elif Score == 0:\n",
    "        TiedGames = TiedGames + 1\n",
    "#Statistics of Game\n",
    "WinTotals = 100*WinningGames/800\n",
    "LostTotals = 100*LosingGames/800\n",
    "TiedTotals = 100*TiedGames/800\n",
    "\n",
    "print('Here are the Scores for Player 1')\n",
    "print(\"------------------------------\")\n",
    "print(\"Wins: {}%\".format(WinTotals))\n",
    "print(\"Losses: {}%\".format(LostTotals))\n",
    "print(\"Ties: {}%\".format(TiedTotals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1B (Solution):**\n",
    "\n",
    "So it seems like we have a higher winning streak! We win a lot more, lose a bit less, and tie with an even smaller probability!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "\n",
    "### (1c) What about playing randomly on different-sized boards?\n",
    "\n",
    "What does the long-term win percentage appear to be for the first player in a 4x4 Tic-Tac-Toe tournament, where 4 marks must be connected for a win?  Support your answer using a simulation and printed output, similar to **2b**.\n",
    "\n",
    "**Also:** The win percentage should have changed substantially. Did the decrease in wins turn into more losses for the first player or more draws? Write a few sentences explaining the behavior you observed.  *Hint: think about how the size of the state space has changed.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the Scores for Player 1\n",
      "------------------------------\n",
      "Wins: 29.625%\n",
      "Losses: 27.5%\n",
      "Ties: 42.875%\n"
     ]
    }
   ],
   "source": [
    "#Winings\n",
    "WinningGames = 0\n",
    "#Losses\n",
    "LosingGames = 0\n",
    "#Ties\n",
    "TiedGames = 0\n",
    "#For 800 games...\n",
    "for i in range(800):\n",
    "    #Play Tic-Tac-Toe on a 4x4 board\n",
    "    GamePlayed = TicTacToe(4,4,4)\n",
    "    #Calculate the Score\n",
    "    Score = GamePlayed.play_game(random_player, random_player)\n",
    "    if Score == 1:\n",
    "        WinningGames = WinningGames + 1\n",
    "    elif Score == -1:\n",
    "        LosingGames = LosingGames + 1\n",
    "    elif Score == 0:\n",
    "        TiedGames = TiedGames + 1\n",
    "#Statistics of Game\n",
    "WinTotals = 100*WinningGames/800\n",
    "LostTotals = 100*LosingGames/800\n",
    "TiedTotals = 100*TiedGames/800\n",
    "\n",
    "print('Here are the Scores for Player 1')\n",
    "print(\"------------------------------\")\n",
    "print(\"Wins: {}%\".format(WinTotals))\n",
    "print(\"Losses: {}%\".format(LostTotals))\n",
    "print(\"Ties: {}%\".format(TiedTotals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1C (Solution):**\n",
    "\n",
    "Wow! Wayyy more Ties this time around! There is a very sharp decline in the Winning Streak we have, because our state space is larger on a $4$x$4$ board, so to achieve a win is going to be a lot harder on a larger board, especially when moves are all randomized too. It's not going to be easier to just win because the state space in itself is bigger. $\\checkmark$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "\n",
    "### (1d) Define an alpha-beta player\n",
    "\n",
    "Alright. Let's finally get serious about our Tic-Tac-Toe game.  No more fooling around!\n",
    "\n",
    "Craft a function called `alphabeta_player` that takes a single argument of a `TicTacToe` class object and returns the minimax move in the `state` of the `TicTacToe` game. As the name implies, this player should be implementing alpha-beta pruning as described in the textbook and lecture.\n",
    "\n",
    "Note that your alpha-beta search for the minimax move should include function definitions for `max_value` and `min_value` (see the aggressively realistic pseudocode from the lecture slides).\n",
    "\n",
    "In your code for the `play_game` method above, make sure that `alphabeta_player` could be a viable input for the `player1` and/or `player2` arguments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SOURCES USED:**\n",
    "\n",
    "1 - (Max/Mins) https://www.geeksforgeeks.org/max-min-python/\n",
    "\n",
    "2 - (Infinity) https://intellipaat.com/community/28852/represent-infinity-as-an-integer-in-python-2-7\n",
    "\n",
    "3 - (AlphaBeta Coding Example Chess) https://www.chessprogramming.org/Alpha-Beta\n",
    "\n",
    "4 - (Minimax Code) https://www.geeksforgeeks.org/minimax-algorithm-in-game-theory-set-4-alpha-beta-pruning/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CODE EXPLANATION:**\n",
    "\n",
    "This was a hard algorithm to implement, but I managed to figure it out by looking at the examples above and researching more into what truly goes into the alphabeta algorithm. I started by defining my max_value and min_value functions inside of alphabeta search. The first thing I did was define alpha, and beta, then I got into my maximizer function.\n",
    "\n",
    "**MAX:**\n",
    "\n",
    "max_value takes alpha, beta, and the state. Game is passed through the parent function so we don't need to pass that into the parameters. The first thing I do is check if the game is over, and if so, return utlility, and None. Then I define some kind of ideal move that we have yet to discover, and my current value. In maximizer, that value is set to -infinity because we know everything will be better than that. I then look through my state moves, find the max between -infinity and whatever is returned from the minimizer (As the algorithm goes). Then I check if I've found a better value from the minimizer than -infinity. My pruning case comes in when we check the current value against beta, and if its bigger than, or equal to beta, we prune and return the new value without looking at the other branches. If so, I update my ideal move to the best maximum, and set alpha to the max between the alpha that was passed in, and the current value. \n",
    "\n",
    "**MIN:**\n",
    "\n",
    "min_value takes alpha, beta, and the state. Game is passed through the parent function so we don't need to pass that into the parameters. The first thing I do is check if the game is over, and if so, return utlility, and None. Then I define some kind of ideal move that we have yet to discover, and my current value. In minimizer, that value is set to +infinity because we know everything will be lower than that. I then look through my state moves, find the min between +infinity and whatever is returned from the maximizer (As the algorithm goes). Then I check if I've found a lower value from the maximizer than +infinity. My pruning case comes in when we check the current value against alpha, and if its less than, or equal to alpha, we prune and return the new value without looking at the other branches. If so, I update my ideal move to the lowest minimum, and set beta to the min between the beta that was passed in, and the current value. \n",
    "\n",
    "Finally, at the end of the function, I check to see if the move was an \"X\" or an \"O\". X is a maximizer, so it calls max, and O is the minimizer, so it calls min. $\\checkmark$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alphabeta_player(game):\n",
    "    return alphabeta_search(game)\n",
    "\n",
    "def alphabeta_search(game):\n",
    "    beta = float('inf')\n",
    "    alpha = -float('inf')\n",
    "    #In-Function Functions that alpha-beta search uses.\n",
    "    def max_value(state, alpha, beta):\n",
    "        #If the game is over, then just return the state utility and none.\n",
    "        if (game.game_over(state)):\n",
    "            return (state.utility, None)\n",
    "        idealMove = None\n",
    "        current = -float('inf')\n",
    "        #For each move in our state moves...\n",
    "        for i in state.moves:\n",
    "            checkerMove = max(current, min_value(game.result(i, state), alpha, beta)[0])\n",
    "            #First we want to see if our current value is equal to the move, if not set it as that first.\n",
    "            if current != checkerMove:\n",
    "                current = checkerMove\n",
    "                #Then set the ideal move to i, and keep going.\n",
    "                idealMove = i\n",
    "            #Now we check if the current value we have is going to be bigger than beta.\n",
    "            #This is the pruning situation.\n",
    "            if current >= beta:\n",
    "                #If it is, set the ideal move to i again, and then return the current value and the ideal move.\n",
    "                idealMove = i\n",
    "                return (current, idealMove)\n",
    "            #Now here is where we pick the maximum of either alpha, or current.\n",
    "            alpha = max(current, alpha)\n",
    "            #Update expanded states!\n",
    "            game.expandedStateVar += 1\n",
    "        #So return this.\n",
    "        return (alpha, idealMove)\n",
    "    def min_value(state, alpha, beta): \n",
    "        #If the game is over, then just return the state utility and none.\n",
    "        if (game.game_over(state)):\n",
    "            return (state.utility, None)\n",
    "        idealMove = None\n",
    "        current = float('inf')\n",
    "        #For each move in our state moves...\n",
    "        for i in state.moves:\n",
    "            checkerMove = min(current, max_value(game.result(i, state), alpha, beta)[0])\n",
    "            if current != checkerMove:\n",
    "                current = checkerMove\n",
    "                idealMove = i\n",
    "            if current <= alpha:\n",
    "                #If it is, set the ideal move to i again, and then return the current value and the ideal move.\n",
    "                idealMove = i\n",
    "                return (current, idealMove)\n",
    "            #Now here is where we pick the maximum of either alpha, or current.\n",
    "            beta = min(current, beta)\n",
    "            #Update expanded states!\n",
    "            game.expandedStateVar += 1\n",
    "        #So return this.\n",
    "        return (beta, idealMove)\n",
    "    if game.state.to_move == \"X\":\n",
    "        score = max_value\n",
    "    #Otherwise, use the min value function.\n",
    "    else:\n",
    "        score = min_value\n",
    "    #Finally, run and see what happens!\n",
    "    x, y = score(game.state, alpha, beta)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that your alpha-beta player code is working appropriately through the following tests, using a standard 3x3 Tic-Tac-Toe board. Run **only 10 games for each test**, and track the number of wins, draws and losses.\n",
    "\n",
    "1. An alpha-beta player who plays first should never lose to a random player who plays second.\n",
    "2. A random player who plays first should never win to an alpha-beta player who plays second.\n",
    "3. Two alpha-beta players should always draw.\n",
    "\n",
    "**Nota bene:** Test your code with fewer games between the players to start, because the alpha-beta player will require substantially more compute time than the random player.  This is why I only ask for 10 games, which still might take a minute or two. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TEST CASE 1 - Alpha vs. Alpha**\n",
    "\n",
    "Below is my testing for an alphabeta vs. alphabeta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alphabeta vs. Alphabeta\n",
      "-------------------------\n",
      "Winnings: 0.0%\n",
      "Losings: 0.0%\n",
      "Ties: 100.0%\n",
      " \n"
     ]
    }
   ],
   "source": [
    "AA_win = 0\n",
    "AA_lose = 0\n",
    "AA_tie = 0\n",
    "for i in range(0,10):\n",
    "    gamePlayed = TicTacToe(3, 3, 3)\n",
    "    score = gamePlayed.play_game(alphabeta_player, alphabeta_player)\n",
    "    if score == 1:\n",
    "        AA_win = AA_win + 1\n",
    "    elif score == -1:\n",
    "        AA_lose = AA_lose + 1\n",
    "    else:\n",
    "        AA_tie = AA_tie + 1 \n",
    "        \n",
    "AA_win_total = (AA_win/10)*100\n",
    "AA_lose_total = (AA_lose/10)*100\n",
    "AA_tie_total = (AA_tie/10)*100\n",
    "\n",
    "print(\"Alphabeta vs. Alphabeta\")\n",
    "print(\"-------------------------\")\n",
    "print(\"Winnings: {}%\".format(AA_win_total))\n",
    "print(\"Losings: {}%\".format(AA_lose_total))\n",
    "print(\"Ties: {}%\".format(AA_tie_total))\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESULTS**\n",
    "\n",
    "\"Two alpha-beta players should always draw, and should always end up in the same terminal state.\"\n",
    "\n",
    "Yup! Ties is 100%. $\\checkmark$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TEST CASE 2 - Alpha vs. Random**\n",
    "\n",
    "Below is my testing for an alphabeta vs. random player. $\\checkmark$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alphabeta vs. Random Player\n",
      "-------------------------\n",
      "Winnings: 100.0%\n",
      "Losings: 0.0%\n",
      "Ties: 0.0%\n",
      " \n"
     ]
    }
   ],
   "source": [
    "AR_win = 0\n",
    "AR_lose = 0\n",
    "AR_tie = 0\n",
    "for i in range(0,10):\n",
    "    gamePlayed = TicTacToe(3, 3, 3)\n",
    "    score = gamePlayed.play_game(alphabeta_player, random_player)\n",
    "    if score == 1:\n",
    "        AR_win = AR_win + 1\n",
    "    elif score == -1:\n",
    "        AR_lose = AR_lose + 1\n",
    "    else:\n",
    "        AR_tie = AR_tie + 1 \n",
    "        \n",
    "AR_win_total = (AR_win/10)*100\n",
    "AR_lose_total = (AR_lose/10)*100\n",
    "AR_tie_total = (AR_tie/10)*100\n",
    "\n",
    "print(\"Alphabeta vs. Random Player\")\n",
    "print(\"-------------------------\")\n",
    "print(\"Winnings: {}%\".format(AR_win_total))\n",
    "print(\"Losings: {}%\".format(AR_lose_total))\n",
    "print(\"Ties: {}%\".format(AR_tie_total))\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESULTS**\n",
    "\n",
    "\"An alpha-beta player who plays first should never lose to a random player who plays second.\"\n",
    "\n",
    "Yup! Alphabeta wins 100% of the time. $\\checkmark$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TEST CASE 3 - Random vs. Alpha**\n",
    "\n",
    "Below is my testing for a random player vs. alphabeta. $\\checkmark$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Player vs. Alphabeta\n",
      "-------------------------\n",
      "Winnings: 0.0%\n",
      "Losings: 100.0%\n",
      "Ties: 0.0%\n"
     ]
    }
   ],
   "source": [
    "RA_win = 0\n",
    "RA_lose = 0\n",
    "RA_tie = 0\n",
    "for i in range(0,10):\n",
    "    gamePlayed = TicTacToe(3, 3, 3)\n",
    "    score = gamePlayed.play_game(random_player, alphabeta_player)\n",
    "    if score == -1:\n",
    "        RA_lose = RA_lose + 1\n",
    "    elif score == 1:\n",
    "        RA_win = RA_win + 1\n",
    "    else:\n",
    "        RA_tie = RA_tie + 1 \n",
    "        \n",
    "RA_win_total = (RA_win/10)*100\n",
    "RA_lose_total = (RA_lose/10)*100\n",
    "RA_tie_total = (RA_tie/10)*100\n",
    "\n",
    "print(\"Random Player vs. Alphabeta\")\n",
    "print(\"-------------------------\")\n",
    "print(\"Winnings: {}%\".format(RA_win_total))\n",
    "print(\"Losings: {}%\".format(RA_lose_total))\n",
    "print(\"Ties: {}%\".format(RA_tie_total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESULTS**\n",
    "\n",
    "\"A random player who plays first should never win to an alpha-beta player who plays second.\"\n",
    "\n",
    "Yup! in my case above, when I executed it, Random Player loses 100% of the time. Sometimes its either a loss or a draw, (Like sometimes I get loss 70% and tie 30%, but never a win.) $\\checkmark$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "\n",
    "### (1e) What has pruning ever done for us?\n",
    "\n",
    "Calculate the number of number of states expanded by the minimax algorithm, with and without pruning, to determine the minimax decision from the initial 3x3 Tic-Tac-Toe board state.  This can be done in many ways, but writing out all the states by hand is **not** one of them (as you will find out!).\n",
    "\n",
    "Write a sentence or two, commenting on the difference in number of nodes expanded by each search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WITH PRUNING:**\n",
    "\n",
    "Let's look at our algorithm from part 1d. We are pruning in this algorithm, so lets let it run and see how many nodes we expand, approximately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alphabeta_player(game):\n",
    "    return alphabeta_search(game)\n",
    "\n",
    "def alphabeta_search(game):\n",
    "    beta = float('inf')\n",
    "    alpha = -float('inf')\n",
    "    #In-Function Functions that alpha-beta search uses.\n",
    "    def max_value(state, alpha, beta):\n",
    "        #If the game is over, then just return the state utility and none.\n",
    "        if (game.game_over(state)):\n",
    "            return (state.utility, None)\n",
    "        idealMove = None\n",
    "        current = -float('inf')\n",
    "        #For each move in our state moves...\n",
    "        for i in state.moves:\n",
    "            #Update expanded states!\n",
    "            game.expandedStateVar += 1\n",
    "            checkerMove = max(current, min_value(game.result(i, state), alpha, beta)[0])\n",
    "            #First we want to see if our current value is equal to the move, if not set it as that first.\n",
    "            if current != checkerMove:\n",
    "                current = checkerMove\n",
    "                #Then set the ideal move to i, and keep going.\n",
    "                idealMove = i\n",
    "            #Now we check if the current value we have is going to be bigger than beta.\n",
    "            #This is the pruning situation.\n",
    "            if current >= beta:\n",
    "                #If it is, set the ideal move to i again, and then return the current value and the ideal move.\n",
    "                idealMove = i\n",
    "                return (current, idealMove)\n",
    "            #Now here is where we pick the maximum of either alpha, or current.\n",
    "            alpha = max(current, alpha)\n",
    "        #So return this.\n",
    "        return (alpha, idealMove)\n",
    "    def min_value(state, alpha, beta): \n",
    "        #If the game is over, then just return the state utility and none.\n",
    "        if (game.game_over(state)):\n",
    "            return (state.utility, None)\n",
    "        idealMove = None\n",
    "        current = float('inf')\n",
    "        #For each move in our state moves...\n",
    "        for i in state.moves:\n",
    "            #Update expanded states!\n",
    "            game.expandedStateVar += 1\n",
    "            checkerMove = min(current, max_value(game.result(i, state), alpha, beta)[0])\n",
    "            if current != checkerMove:\n",
    "                current = checkerMove\n",
    "                idealMove = i\n",
    "            if current <= alpha:\n",
    "                #If it is, set the ideal move to i again, and then return the current value and the ideal move.\n",
    "                idealMove = i\n",
    "                return (current, idealMove)\n",
    "            #Now here is where we pick the maximum of either alpha, or current.\n",
    "            beta = min(current, beta)\n",
    "        #So return this.\n",
    "        return (beta, idealMove)\n",
    "    if game.state.to_move == 'X':\n",
    "        score = max_value\n",
    "    #Otherwise, use the min value function.\n",
    "    else:\n",
    "        score = min_value\n",
    "    #Finally, run and see what happens!\n",
    "    x, y = score(game.state, alpha, beta)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TESTING: PRUNING**\n",
    "\n",
    "Let's test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning expands approx. 18296 states.\n"
     ]
    }
   ],
   "source": [
    "#Let's do the pruning.\n",
    "withPruning = TicTacToe(3,3,3)\n",
    "#Call the function\n",
    "alphabeta_player(withPruning)\n",
    "#Print\n",
    "print(\"Pruning expands approx. {} states.\".format(withPruning.expandedStateVar))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WITHOUT PRUNING:**\n",
    "\n",
    "Let's look at our algorithm from part 1d. We are pruning in this algorithm, but if we get rid of the case of pruning entirely (everywhere we do a comparison between our current value and alpha or beta). So lets take that part of the code out, and let it run and see how many nodes we expand, approximately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alphabeta_player(game):\n",
    "    return alphabeta_search(game)\n",
    "\n",
    "def alphabeta_search(game):\n",
    "    beta = float('inf')\n",
    "    alpha = -float('inf')\n",
    "    #In-Function Functions that alpha-beta search uses.\n",
    "    def max_value(state, alpha, beta):\n",
    "        #If the game is over, then just return the state utility and none.\n",
    "        if (game.game_over(state)):\n",
    "            return (state.utility, None)\n",
    "        idealMove = None\n",
    "        current = -float('inf')\n",
    "        #For each move in our state moves...\n",
    "        for i in state.moves:\n",
    "            #Update expanded states!\n",
    "            game.expandedStateVar += 1\n",
    "            checkerMove = max(current, min_value(game.result(i, state), alpha, beta)[0])\n",
    "            #First we want to see if our current value is equal to the move, if not set it as that first.\n",
    "            if current != checkerMove:\n",
    "                current = checkerMove\n",
    "                #Then set the ideal move to i, and keep going.\n",
    "                idealMove = i\n",
    "            #Now we check if the current value we have is going to be bigger than beta.\n",
    "            #Now here is where we pick the maximum of either alpha, or current.\n",
    "            alpha = max(current, alpha)\n",
    "        #So return this.\n",
    "        return (alpha, idealMove)\n",
    "    def min_value(state, alpha, beta): \n",
    "        #If the game is over, then just return the state utility and none.\n",
    "        if (game.game_over(state)):\n",
    "            return (state.utility, None)\n",
    "        idealMove = None\n",
    "        current = float('inf')\n",
    "        #For each move in our state moves...\n",
    "        for i in state.moves:\n",
    "            #Update expanded states!\n",
    "            game.expandedStateVar += 1\n",
    "            checkerMove = min(current, max_value(game.result(i, state), alpha, beta)[0])\n",
    "            if current != checkerMove:\n",
    "                current = checkerMove\n",
    "                idealMove = i\n",
    "            #Now here is where we pick the maximum of either alpha, or current.\n",
    "            beta = min(current, beta)\n",
    "        #So return this.\n",
    "        return (beta, idealMove)\n",
    "    if game.state.to_move == 'X':\n",
    "        score = max_value\n",
    "    #Otherwise, use the min value function.\n",
    "    else:\n",
    "        score = min_value\n",
    "    #Finally, run and see what happens!\n",
    "    x, y = score(game.state, alpha, beta)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TESTING: WITHOUT PRUNING**\n",
    "\n",
    "Let's test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without Pruning expands approx. 549945 states.\n"
     ]
    }
   ],
   "source": [
    "#Let's do without pruning.\n",
    "withoutPruning = TicTacToe(3,3,3)\n",
    "#Call the function\n",
    "alphabeta_player(withoutPruning)\n",
    "#Print\n",
    "print(\"Without Pruning expands approx. {} states.\".format(withoutPruning.expandedStateVar))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CONCLUSION:**\n",
    "\n",
    "To reiterate, with pruning, we expanded 18,296 states, and without pruning, we expanded 549,945 states. That is a MASSIVE difference, and one that we expect because pruning cuts the amount of branches we need to explore when it finds the best option (lowest min possible or highest max possible). When you don't have pruning, you would need to explore states that won't make any change to the value the minimizer or maximizer has already chosen, so it seems futile to explore those. Hence pruning really does save the amount of work we have to do in this algorithm. $\\checkmark$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "## Problem 2 (30 points):  Uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2a) \n",
    "\n",
    "Suppose you are deciding when to arrive at a party. There is some optimal time to arrive when the loss you feel, as measured by _awkwardness_, is minimized at 0. That is, at some particular time, it is not awkward at all to show up to the party. The awkwardness (loss) increases as you arrive too early or too late relative to this optimal time. What is a suitable loss function, $L(d, x)$, to model this situation? Include definitions for $d$ and $x$, consistent with the examples from this class. Use this loss function this weekend when you go out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2a (Solution):**\n",
    "\n",
    "$d$ is going to represent the loss, or in our case, the awkwardness. $x$ is going to represent the arrival time.\n",
    "\n",
    "One way of doing this is making a Quadratic Function for Loss, where you have...\n",
    "\n",
    "$$L(d,x) = (d-x)^2$$\n",
    "\n",
    "This checks out! $\\checkmark$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2b)\n",
    "\n",
    "Suppose we have a situation where loss is given by the function $L(d, x) = 2(d-x)^2$. Set up, simplify, and evaluate integral(s) for the expected loss, $E_x[L(d, x)]$, where your prior beliefs regarding $x$ follow the distribution $f(x)$ given below. You may assume $f(x)=0$ for values of $x$ outside of the interval $[0, 3]$.\n",
    "\n",
    "f(x) =  \\begin{cases} \n",
    "      1/2 & 0 \\leq x <1 \\\\\n",
    "      3/8 & 1 \\leq x <2 \\\\\n",
    "      1/8 & 2 \\leq x \\leq 3 \n",
    "   \\end{cases}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\int_{0}^{1} 2(d-x)^2 \\cdot \\frac{1}{2} dx + \\int_{1}^{2} 2(d-x)^2 \\cdot \\frac{3}{8} dx + \\int_{2}^{3} 2(d-x)^2 \\cdot \\frac{1}{8} dx$$\n",
    "\n",
    "$$-\\frac{\\left(d-1\\right)^3}{3}+\\frac{d^3}{3} + -\\frac{\\left(d-2\\right)^3-\\left(d-1\\right)^3}{4} + -\\frac{\\left(d-3\\right)^3-\\left(d-2\\right)^3}{12}$$\n",
    "\n",
    "Get everything to the same denominator so you can add it. So this is...\n",
    "\n",
    "$$(\\frac{4}{4} \\cdot -\\frac{\\left(d-1\\right)^3}{3}) + (\\frac{4}{4} \\cdot \\frac{d^3}{3}) + (\\frac{3}{3} \\cdot -\\frac{\\left(d-2\\right)^3-\\left(d-1\\right)^3}{4}) + -\\frac{\\left(d-3\\right)^3-\\left(d-2\\right)^3}{12}$$\n",
    "\n",
    "Now everything has correct denominator.\n",
    "\n",
    "$$-\\frac{4\\left(d-1\\right)^3}{12}+\\frac{4d^3}{12} -\\frac{3\\left(d-2\\right)^3-\\left(d-1\\right)^3}{12} -\\frac{\\left(d-3\\right)^3-\\left(d-2\\right)^3}{12}$$\n",
    "\n",
    "Write it all over 12.\n",
    "\n",
    "$$\\frac{-4\\left(d-1\\right)^3 + 4d^3 - 3\\left(d-2\\right)^3-\\left(d-1\\right)^3 - \\left(d-3\\right)^3-\\left(d-2\\right)^3}{12}$$\n",
    "\n",
    "Once that's expanded out we get...\n",
    "\n",
    "$$-\\frac{d^3}{2}+4d^2-\\frac{15d}{2}+\\frac{16}{3}$$\n",
    "\n",
    "So that is going to be our expected loss, in terms of $d \\checkmark$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2c) \n",
    "\n",
    "Suppose our expected loss is represented by the function $E_x[(L(d,x)]=(2-d)^2+2$, and our prior beliefs regarding $x$ are given by the distribution $f(x)$ from part b.\n",
    "\n",
    "- Calculate Bayes' Decision, $d_{Bayes}$.\n",
    "\n",
    "- Calculate the Expected Value of Including Uncertainty, EVIU. Suppose that if we ignore uncertainty, our best guess for what decision to make is the median of $x$ (under our prior $f(x)$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2c (Solution):**\n",
    "\n",
    "$d_{bayes}$ is the minimum value of this function. The most minimum it can be is when $d$ is 2, because then you'll get...\n",
    "\n",
    "$$(2-2)^2+2 = 0$$\n",
    "\n",
    "It can not come lower than that. So $d_{bayes}=2 \\checkmark$\n",
    "\n",
    "Now for $EVIU$, we know the median is going to be $1$ based off our $f(x)$, and we know that the formula for $EVIU$ is $E_x[L(d_{iu},x)] - E_x[L(d_{Bayes},x)]$. Because our loss function is a quadratic, as discussed in the lecture, this implies symmetry, where $d_{iu} = d_{bayes} = E_x[x]$, so that means it's going to be $0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Problem 3 (35 points): Maximizing some objective function with a Genetic Algorithm\n",
    "\n",
    "Suppose we are trying to figure out a cookie recipe, but can't quite remember how much of each ingredient we need.\n",
    "\n",
    "So we want to maximize the following objective function corresponding to how close we are to this recipe:\n",
    "\n",
    "* 3/4 cup granulated sugar (36 tsp)\n",
    "* 3/4 cup packed brown sugar  (36 tsp)\n",
    "* 1 cup butter (48 tsp)\n",
    "* 1 teaspoon vanilla (1 tsp)\n",
    "* 1 egg\n",
    "* 2 1/4 cups flour (108 tsp)\n",
    "* 1 teaspoon baking soda (1 tsp)\n",
    "* 1/2 teaspoon salt (0.5 tsp)\n",
    "* 1 package (12 ounces) chocolate chips (2 cups) (96 tsp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = [36, 36, 48, 1, 1, 108, 1, 0.5, 96]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example starting state for a member of our population might look like: $state = [30, 30, 40, 1, 0, 100, 0.5, 0.5, 100]$\n",
    "\n",
    "### (3a) \n",
    "\n",
    "Write an objective function `def recipe_success(state)` that takes a single argument state, and returns the objective function value (fitness) of the state. The objective function should be maximized when a state reaches the target. You could for example define the fitness score of a particular state based on how far away each entry is from the target recipe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3A (Solution):**\n",
    "\n",
    "I want to explain my code and how I wrote my fitness function. My fitness function takes some state of 9 ingredients, and compares those 9 ingredients to the 9 ingredients in our target recipe! So what this function returns is a fitness score of 9 elements that is the difference between target and state. Ideally what we want our genetic algorithm to do is to achieve a fitness score of 1000. Meaning there's no difference between the target and state values, but... we will have to see if that ends up happening. $\\checkmark$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recipe_success(state):\n",
    "    #Let's start with a fitness of 100.\n",
    "    fitnessScore = 100\n",
    "    #For each element in the state...\n",
    "    for i in range(len(state)):\n",
    "        #For each state and target, find the difference between the two.\n",
    "        subScore = state[i] - target[i]\n",
    "        #If the difference is not 0, then find the fitnessScore by subtracting the absolute value of it.\n",
    "        if subScore!=0:\n",
    "            #Find the fitness score\n",
    "            fitnessScore = fitnessScore - subScore\n",
    "            #Take absolute value of it.\n",
    "            fitnessScore = abs(fitnessScore)\n",
    "        #If it is zero, then add 100.\n",
    "        else:\n",
    "            #So in the end we should have 1000 as our goal, if all elements match.\n",
    "            fitnessScore = fitnessScore + 100\n",
    "    #return the score of fitness.\n",
    "    return fitnessScore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3b) \n",
    "\n",
    "Using our in class notebook \"CSCI3202_GeneticAlgorithm.ipynb\" as your guide, write a genetic algorithm that starts with a population of 10 randomly generated \"recipes/states/members\" and uses the objective function you wrote in **(3a)** to hopefully hit the target after a certain number of generations. \n",
    "\n",
    "Key components of your code:\n",
    "- Generate the initial population randomly from numbers between 0 and 108 (half step intervals might be helpful since the recipe requires 1/2 tsp salt)\n",
    "- Allow for mutations in your population with an overall probability of mutation set to p = 0.1\n",
    "- Choose 2 \"parents\" in the generation of each \"child\"\n",
    "- Choose a random split point at which to combine the two \"parents\"\n",
    "- Run the algorithm for 200 iterations (\"generations\"). Do you hit your target?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SOURCES USED:**\n",
    "\n",
    "1 - (arange) https://docs.scipy.org/doc/numpy/reference/generated/numpy.arange.html\n",
    "\n",
    "2 - (split) https://www.geeksforgeeks.org/python-custom-list-split/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reproduce\n",
    "def reproduce(paren_1, paren_2):\n",
    "    #   - 2 parents\n",
    "    splittedValue = np.random.randint(low=1, high=len(paren_1))\n",
    "    #   - Split parents 1 and 2\n",
    "    firstHalf = paren_1[:splittedValue]\n",
    "    #   - Find First Half (parent1) and Second Half (parent2)\n",
    "    secondHalf = paren_2[splittedValue:]\n",
    "    #   - Child is the First Half + Second Half\n",
    "    childVal = firstHalf + secondHalf\n",
    "    #Return Child\n",
    "    return childVal\n",
    "\n",
    "#Mutation\n",
    "def mutate(childVal, sample_space):\n",
    "    #   - Gene is the random int from 0 to child value\n",
    "    geneValue = np.random.randint(low=0, high=len(childVal))\n",
    "    #   - Mutate the child at the gene value chosen above from a member of sample space\n",
    "    childVal[geneValue]=random.choice(sample_space)\n",
    "    #Return Child\n",
    "    return childVal\n",
    "\n",
    "#Fitness\n",
    "def fitness(population):\n",
    "    #   - Reproduction Array\n",
    "    p_reproduce = []\n",
    "    #   - Fitness Array\n",
    "    fitnessArr = []\n",
    "    #   - For each i in the population\n",
    "    for i in range(len(population)):\n",
    "         #   - Performance is recipe_success of population at i.\n",
    "        performanceVal = recipe_success(population[i])\n",
    "         #   - Append performance to fitness array\n",
    "        fitnessArr.append(performanceVal)\n",
    "     #   - Sum up all the fitnesses\n",
    "    totalSum = sum(fitnessArr)\n",
    "     #   - For j in fitness array\n",
    "    for j in fitnessArr:\n",
    "        #Reproduce is gonna be the element of fitness over total sum\n",
    "        reproduce = j/totalSum\n",
    "        #Fitness Total is the appended reproduce\n",
    "        fitnessTot = p_reproduce.append(reproduce)\n",
    "    return fitnessTot\n",
    "\n",
    "def genetic_algorithm(population, n_init, mutationProbability, populationSize, num_of_iterations, targetValue):\n",
    "    samplePopulation = []\n",
    "    #Population array\n",
    "    poparr = []\n",
    "    #Use arange to get step size of 0.5\n",
    "    for member in np.arange(0, population, 0.5):\n",
    "        #append the member to sample population\n",
    "        samplePopulation.append(member)\n",
    "    #for each val in population size\n",
    "    for each in range(populationSize):\n",
    "        #Initial pop arr\n",
    "        initPop=[]\n",
    "        #For each in n_init\n",
    "        for k in range(n_init):\n",
    "            #Pick random and append it to init pop\n",
    "            rand = random.choice(samplePopulation)\n",
    "            initPop.append(rand)\n",
    "        poparr.append(initPop)\n",
    "    #For i in iterations\n",
    "    for i in range(num_of_iterations):\n",
    "        #New generation declaration\n",
    "        generation_new = []\n",
    "        for j in range(populationSize):\n",
    "            #Reproduction is the fitness score of pop arr\n",
    "            reproduction = fitness(poparr)\n",
    "            #Parent results is going to be random choice to pick parents\n",
    "            parentResults = np.random.choice(range(0, populationSize), size=2, p=reproduction, replace=False)\n",
    "            #Parents 1 and 2 will come from the pop array\n",
    "            paren1,paren2 = poparr[parentResults[0]], poparr[parentResults[1]]\n",
    "            #Child will be reproduced in function\n",
    "            child = reproduce(paren1, paren2)\n",
    "            #Mutation here to pick if the mutation takes place, its either true of false\n",
    "            sub = 1-mutationProbability\n",
    "            mutation = np.random.choice([True,False], p=[mutationProbability, sub])\n",
    "            #If mutation is true\n",
    "            if mutation:\n",
    "                #Then child is the mutation\n",
    "                child = mutate(child, samplePopulation)\n",
    "            #Append the child to new generation\n",
    "            generation_new.append(child)\n",
    "        #Update population array\n",
    "        poparr=generation_new\n",
    "        #Get performance\n",
    "        performance=[recipe_success(member) for member in poparr]\n",
    "        best_member=max(zip(performance,poparr))\n",
    "        if best_member[0]>=targetValue:\n",
    "            return best_member\n",
    "    print(\"reached n_iter\")\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are...\n",
      "-----------\n",
      "reached n_iter\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(\"Results are...\")\n",
    "print(\"-----------\")\n",
    "test1 = genetic_algorithm(population=108, n_init=9, mutationProbability=0.1, populationSize=10, num_of_iterations=200, targetValue=1000)\n",
    "print(test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3b (Solution):**\n",
    "\n",
    "Nope, not hitting the target yet... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3c)\n",
    "\n",
    "Report the following:\n",
    "- Report whether you minimized of maximized the objective function and whether that led to any major changes in how you designed the probability of reproduction. A couple sentences here is fine.\n",
    "\n",
    "- Report how many ingredients you ended up matching. e.g. target = [36, 36, 48, 1, 1, 108, 1, 0.5, 96], perhaps your algorithm achieved [36, 42, 8, 1, 1, 100, 56, 0.5, 0], then you would have matched 4 of the ingredient values.\n",
    "\n",
    "- Report how many iterations you tried in order to get this answer. (Don't burn up your machine in the process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I'm going to re-implement my code with matching.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match found! Ingredient 7 with value [0.5] was matched on iteration 3\n",
      "match found! Ingredient 7 with value [0.5] was matched on iteration 4\n",
      "match found! Ingredient 7 with value [0.5] was matched on iteration 5\n",
      "match found! Ingredient 7 with value [0.5] was matched on iteration 6\n",
      "match found! Ingredient 7 with value [0.5] was matched on iteration 7\n",
      "match found! Ingredient 7 with value [0.5] was matched on iteration 8\n",
      "match found! Ingredient 7 with value [0.5] was matched on iteration 9\n",
      "match found! Ingredient 2 with value [48.0] was matched on iteration 195\n",
      "match found! Ingredient 2 with value [48.0] was matched on iteration 196\n",
      "match found! Ingredient 2 with value [48.0] was matched on iteration 197\n",
      "match found! Ingredient 4 with value [1.0] was matched on iteration 276\n",
      "reached n_iter\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Your code here.\n",
    "def reproduce(paren_1, paren_2):\n",
    "    #   - 2 parents\n",
    "    splittedValue = np.random.randint(low=1, high=len(paren_1))\n",
    "    #   - Split parents 1 and 2\n",
    "    firstHalf = paren_1[:splittedValue]\n",
    "    #   - Find First Half (parent1) and Second Half (parent2)\n",
    "    secondHalf = paren_2[splittedValue:]\n",
    "    #   - Child is the First Half + Second Half\n",
    "    childVal = firstHalf + secondHalf\n",
    "    #Return Child\n",
    "    return childVal\n",
    "\n",
    "#Mutation\n",
    "def mutate(childVal, sample_space):\n",
    "    #   - Gene is the random int from 0 to child value\n",
    "    geneValue = np.random.randint(low=0, high=len(childVal))\n",
    "    #   - Mutate the child at the gene value chosen above from a member of sample space\n",
    "    childVal[geneValue]=random.choice(sample_space)\n",
    "    #Return Child\n",
    "    return childVal\n",
    "\n",
    "#Fitness\n",
    "def fitness(population):\n",
    "    #   - Reproduction Array\n",
    "    p_reproduce = []\n",
    "    #   - Fitness Array\n",
    "    fitnessArr = []\n",
    "    #   - For each i in the population\n",
    "    for i in range(len(population)):\n",
    "         #   - Performance is recipe_success of population at i.\n",
    "        performanceVal = recipe_success(population[i])\n",
    "         #   - Append performance to fitness array\n",
    "        fitnessArr.append(performanceVal)\n",
    "     #   - Sum up all the fitnesses\n",
    "    totalSum = sum(fitnessArr)\n",
    "     #   - For j in fitness array\n",
    "    for j in fitnessArr:\n",
    "        #Reproduce is gonna be the element of fitness over total sum\n",
    "        reproduce = j/totalSum\n",
    "        #Fitness Total is the appended reproduce\n",
    "        fitnessTot = p_reproduce.append(reproduce)\n",
    "    return fitnessTot\n",
    "\n",
    "def genetic_algorithm(population, n_init, mutationProbability, populationSize, num_of_iterations, targetValue):\n",
    "    samplePopulation = []\n",
    "    #Population array\n",
    "    poparr = []\n",
    "    #Use arange to get step size of 0.5\n",
    "    for member in np.arange(0, population, 0.5):\n",
    "        #append the member to sample population\n",
    "        samplePopulation.append(member)\n",
    "    #for each val in population size\n",
    "    for each in range(populationSize):\n",
    "        #Initial pop arr\n",
    "        initPop=[]\n",
    "        #For each in n_init\n",
    "        for k in range(n_init):\n",
    "            #Pick random and append it to init pop\n",
    "            rand = random.choice(samplePopulation)\n",
    "            initPop.append(rand)\n",
    "        poparr.append(initPop)\n",
    "    #For i in iterations\n",
    "    for i in range(num_of_iterations):\n",
    "        #New generation declaration\n",
    "        generation_new = []\n",
    "        for j in range(populationSize):\n",
    "            #Reproduction is the fitness score of pop arr\n",
    "            reproduction = fitness(poparr)\n",
    "            #Parent results is going to be random choice to pick parents\n",
    "            parentResults = np.random.choice(range(0, populationSize), size=2, p=reproduction, replace=False)\n",
    "            #Parents 1 and 2 will come from the pop array\n",
    "            paren1,paren2 = poparr[parentResults[0]], poparr[parentResults[1]]\n",
    "            #Child will be reproduced in function\n",
    "            child = reproduce(paren1, paren2)\n",
    "            #Mutation here to pick if the mutation takes place, its either true of false\n",
    "            sub = 1-mutationProbability\n",
    "            mutation = np.random.choice([True,False], p=[mutationProbability, sub])\n",
    "            #If mutation is true\n",
    "            if mutation:\n",
    "                #Then child is the mutation\n",
    "                child = mutate(child, samplePopulation)\n",
    "            #Append the child to new generation\n",
    "            generation_new.append(child)\n",
    "        #Update population array\n",
    "        poparr=generation_new\n",
    "        #Get performance\n",
    "        performance=[recipe_success(member) for member in poparr]\n",
    "        best_member=max(zip(performance,poparr))\n",
    "        if best_member[0]>=targetValue:\n",
    "            return best_member\n",
    "        target = [36, 36, 48, 1, 1, 108, 1, 0.5, 96]\n",
    "        #Implementing Matching\n",
    "        matchedVals = []\n",
    "        for o in range(0,9):\n",
    "            if target[o]==best_member[1][o]:\n",
    "                matchedVals.append(best_member[1][o])\n",
    "                print(\"match found! Ingredient {} with value {} was matched on iteration {}\".format(o,matchedVals, i))\n",
    "    print(\"reached n_iter\")\n",
    "    return False\n",
    "\n",
    "test1 = genetic_algorithm(population=108, n_init=9, mutationProbability=0.1, populationSize=10, num_of_iterations=400, targetValue=1000)\n",
    "print(test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3C (Solution):**\n",
    "\n",
    "I maximized the objective function because I wanted the fitness score to be greater than its initial value by the time genetic algorithm has run. Ideally you'd want a score of 1000 at the end, (where the initial fitness score starts at 100 and adds 100 each time an element matches) but I haven't gotten close to that yet. It didn't really lead to major changing in reproduction, I just split the parents and made the child, regardless. $\\checkmark$\n",
    "\n",
    "In regards to matching, I've matched quite a few ingredients actually! Like when I ran it above, its matching different ingredients per different iteration! Like for instance, a sample result I got is.. \n",
    "\n",
    "**A sample output of my code:**\n",
    "\n",
    "match found! Ingredient 7 with value [0.5] was matched on iteration 8\n",
    "\n",
    "match found! Ingredient 7 with value [0.5] was matched on iteration 9\n",
    "\n",
    "match found! Ingredient 2 with value [48.0] was matched on iteration 195\n",
    "\n",
    "match found! Ingredient 2 with value [48.0] was matched on iteration 196\n",
    "\n",
    "match found! Ingredient 2 with value [48.0] was matched on iteration 197\n",
    "\n",
    "match found! Ingredient 4 with value [1.0] was matched on iteration 276\n",
    "\n",
    "\n",
    "So I am definitely finding matches! Ingredients I'm matching on are 1 cup butter (48 tsp)\n",
    "1 teaspoon vanilla (1 tsp), 1 egg, and a pkg of chocolate chips. Mostly I match on the ingredients with $1$, but I am matching other things from time to time as well.  I am doing it over $400$ iterations, but honestly even if I do about $200$, I still can find them. $\\checkmark$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
